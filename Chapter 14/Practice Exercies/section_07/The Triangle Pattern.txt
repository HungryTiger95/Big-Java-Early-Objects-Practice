Let us see if we can speed up the algorithm from the preceding section. It seems
wasteful to count elements again if we have already counted them.

Can we save time by eliminating repeated counting of the same element? That is,
before counting a[i], should we first check that it didn't occur in a[0] ... a[i - 1]?

Let us estimate the cost of these additional checks. In the ith step, the amount of
work is proportional to i.

To get an intuitive feel for this situation. In the second iteration, we visit a[0]
again. In the third iteration, we visit a[0] and a[1] again, and so on.

A loop with n iterations has O(n^2) running time if the ith step takes O(i) time.

Here is another idea for time saving. When we count a[i], there is no need to do
the counting in a[0] ... a[i -1]. If a[i] never occurred before, we get an accurate
count by just looking at a[i] ... a[i - 1]. And if it did, we already have an accurate
count. Does that help us? Not really -- it's the triangle pattern again, but this time
in the other direction. That doesn't mean that these improvements aren't worthwhile.
If an O(n^2). algorithm is the best one can do for a particular problem, you still
want to make it as fast as possible.