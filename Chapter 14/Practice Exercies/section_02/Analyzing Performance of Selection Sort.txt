Let us count the number of operations that the program must carry out to sort an array
with the selection sort algorithm. We don't actually know how many machine operations
are generated for each Java instruction, or which of those instructions are more
time-consuming than others, but we can make a simplification. We will simply count
how often an array element is visited.

Let n be the size of the array First, we must find the smallest of n numbers. To
achieve that, we must visit n array elements. Then we swap the elements, which takes
two visits. In the next step, we need to visit only n - 1 elements to find the minimum.
In the following step, n - 2 elements are visited to find the minimum. The last step
visits two elements to find the minimum. Each step requires two visits to swap the
elements. Therefore, the total number of visits is:

		n + 2 + (n - 1) + 2 + ... + 2 + 2 = n + (n - 1) + ... + 2 + (n - 1) * 2
			                              = 2 + ... + (n - 1) + n + (n - 1) * 2
			                              = (n(n + 1) / 2) - 1 + (n - 1) * 2
			                         
because

				1 + 2 + ... + (n-1) + n = (n(n - 1)) / 2
				
After multiplying out and collecting terms of n, we find that the number of visits is:

				(1 / 2)(n^2) + (5 / 2)(n) - 3
				
We obtain a quadratic equation in n.

Now simplify the analysis further. When you plug in a large value for n (for example, 1,000
and 2,000), then (1 /2)(n^2) is 500,000 or 2,000,000. The lower term, (5 / 2)(n) - 3,
doesn't contribute much at all; it is only 2,497 or 4,997, a drop in the bucket compared
to the hundreds of thousands or even millions of comparisons specified by the (1 / 2)(n^2)
term. We will just ignore these lower-level terms. Next, we will ignore the constant
factor (1 / 2). We want to compare the ratios of counts for different values of n. For
example, we can say that sorting an array of 2,000 numbers requires four times as many
visits as sorting an array of 1,000 numbers. The number of visits is of order of n^2.

To indicate that the number of visits is of order n^2, computer scientists often use
big-Oh notation: The number of visits is O(n^2).

To turn a polynomial expression such as:

		(1 / 2)(n^2) + (5 / 2)(n) - 3
		
into big-Oh notation, simply locate the fastest-growing term, n^2, and ignore its
constant coefficient, no matter how large or small it may be.

Selection sort is an O(n^2) algorithm. Doubling the data set means a fourfold increase
in processing time.